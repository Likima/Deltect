{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d2564a1",
   "metadata": {},
   "source": [
    "# Deltect: Genomic Deletion Pathogenicity Classifier\n",
    "This notebook demonstrates how to interact with the tool "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256550a3",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "First, install all the required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0204569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.13.9 environment at: /home/tangb/Deltect/.venv\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m26 packages\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies using uv\n",
    "!uv pip install -r ../requirements.txt\n",
    "\n",
    "# or use pip\n",
    "# !pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dec7f7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version: 3.13.9 (main, Nov 19 2025, 22:47:49) [Clang 21.1.4 ]\n",
      "Added to path: /home/tangb/Deltect\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pysam: 0.23.3\n",
      "scikit-learn: 1.7.2\n",
      "pandas: 2.3.3\n",
      "numpy: 2.3.4\n",
      "All dependencies installed!\n"
     ]
    }
   ],
   "source": [
    "# verify that the installation worked:\n",
    "\n",
    "import sys\n",
    "print(f\"python version: {sys.version}\")\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "parent_dir = Path.cwd().parent\n",
    "\n",
    "# Add to Python path if not already there\n",
    "if str(parent_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(parent_dir))\n",
    "\n",
    "print(f\"Added to path: {parent_dir}\")\n",
    "\n",
    "# check required packages\n",
    "import pysam\n",
    "import sklearn\n",
    "import pandas as pd   \n",
    "import numpy as np \n",
    "\n",
    "print(f\"pysam: {pysam.__version__}\")\n",
    "print(f\"scikit-learn: {sklearn.__version__}\")\n",
    "print(f\"pandas: {pd.__version__}\")\n",
    "print(f\"numpy: {np.__version__}\")\n",
    "\n",
    "print(\"All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb4fe70",
   "metadata": {},
   "source": [
    "## 2. Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f5d1300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.api import fetch_clinvar_deletions_entrez\n",
    "from data.data_processor import pass_through_variants\n",
    "from data.preprocessing import summarize_variants\n",
    "from extraction.deletion_extraction import DeletionExtractor\n",
    "from training.model import DeletionPathogenicityPredictor\n",
    "\n",
    "# import the config vars\n",
    "import config  \n",
    "\n",
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd868b86",
   "metadata": {},
   "source": [
    "Run the following command to download the genomic files used for training and prediction.\n",
    "```bash\n",
    "./download_references.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fe05de",
   "metadata": {},
   "source": [
    "## 3. Manual Pipeline Implementation (For Demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f87f2959",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data.api:Initialized ClinVarClient with email: tangbrandonk@gmail.com\n",
      "INFO:data.api:Found 9559 variant IDs, fetching in batches of 200...\n",
      "INFO:data.api:Fetched 9559 pathogenic variants\n",
      "INFO:data.api:Found 1659 variant IDs, fetching in batches of 200...\n",
      "INFO:data.api:Fetched 1659 non-pathogenic variants\n",
      "INFO:data.api:Total variants fetched: 11218 (pathogenic: 9559, non-pathogenic: 1659)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11218 variants\n"
     ]
    }
   ],
   "source": [
    "from data.api import ClinVarClient\n",
    "\n",
    "client = ClinVarClient(\"../.env\") # instantiate a clinvar client\n",
    "\n",
    "variants = []\n",
    "\n",
    "for chr in config.CHROMOSOMES:\n",
    "    variants.extend(client.fetch_deletion_variants(17, config.MAX_VARIANTS_PER_CHR))\n",
    "\n",
    "print(f\"There are {len(variants)} variants\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3799611",
   "metadata": {},
   "source": [
    "## 4 Filter the variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e2ede92",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_variants = pass_through_variants(variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d4c0108",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data.ref_genome_data:Loading reference genome: ../hs37d5.fa\n",
      "INFO:data.ref_genome_data:Using FASTA index file\n",
      "INFO:data.ref_genome_data:Loaded 1 chromosomes\n",
      "INFO:data.ref_genome_data:  chr17: 81,195,210 bp\n",
      "INFO:data.ref_genome_data:Matching 7852 reference samples to STR distribution\n",
      "INFO:data.ref_genome_data:STR length range: 1-15541116 bp\n",
      "INFO:data.ref_genome_data:Matched 500/7852 samples\n",
      "INFO:data.ref_genome_data:Matched 1000/7852 samples\n",
      "INFO:data.ref_genome_data:Matched 1500/7852 samples\n",
      "INFO:data.ref_genome_data:Matched 2000/7852 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4/5] Sampling normal reference sequences...\n",
      "Reference genome: ../hs37d5.fa\n",
      "Sampling 11218 normal sequences to match deletion distribution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data.ref_genome_data:Matched 2500/7852 samples\n",
      "INFO:data.ref_genome_data:Matched 3000/7852 samples\n",
      "INFO:data.ref_genome_data:Matched 3500/7852 samples\n",
      "INFO:data.ref_genome_data:Matched 4000/7852 samples\n",
      "INFO:data.ref_genome_data:Matched 4500/7852 samples\n",
      "INFO:data.ref_genome_data:Matched 5000/7852 samples\n",
      "INFO:data.ref_genome_data:Matched 5500/7852 samples\n",
      "INFO:data.ref_genome_data:Matched 6000/7852 samples\n",
      "INFO:data.ref_genome_data:Matched 6500/7852 samples\n",
      "INFO:data.ref_genome_data:Matched 7000/7852 samples\n",
      "INFO:data.ref_genome_data:Matched 7500/7852 samples\n",
      "INFO:data.ref_genome_data:Sampled 7852 regions in 8192 attempts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 7852 normal reference sequences\n",
      "\n",
      "Combined dataset: 19070 total samples\n",
      "  ClinVar variants: 11218\n",
      "  Reference benign: 7852\n"
     ]
    }
   ],
   "source": [
    "from config import CHROMOSOMES\n",
    "from data.ref_genome_data import ReferenceGenomeSampler\n",
    "\n",
    "\n",
    "print(f\"\\n[4/5] Sampling normal reference sequences...\")\n",
    "print(f\"Reference genome: {\"../hs37d5.fa\"}\")\n",
    "\n",
    "all_training_variants = []\n",
    "\n",
    "try:\n",
    "    if not Path(\"../hs37d5.fa\").exists():\n",
    "        print(f\"WARNING: Reference genome not found: ../hs37d5.fa\")\n",
    "        print(\"Skipping reference genome sampling.\")\n",
    "    else:\n",
    "        # Initialize reference sampler\n",
    "        sampler = ReferenceGenomeSampler(\n",
    "            reference_fasta=\"../hs37d5.fa\",\n",
    "            chromosomes=CHROMOSOMES\n",
    "        )\n",
    "        \n",
    "        # Match deletion distribution\n",
    "        num_normal_samples = len(processed_variants)\n",
    "        print(f\"Sampling {num_normal_samples} normal sequences to match deletion distribution...\")\n",
    "        \n",
    "        # In your notebook, change ratio from 1.0 to 0.3-0.5\n",
    "        normal_sequences = sampler.match_str_distribution(\n",
    "            str_variants=processed_variants,\n",
    "            ratio=0.7\n",
    "        )\n",
    "        \n",
    "        print(f\"Sampled {len(normal_sequences)} normal reference sequences\")\n",
    "        \n",
    "        \n",
    "        # Combine with processed variants\n",
    "        all_training_variants = processed_variants + normal_sequences\n",
    "        print(f\"\\nCombined dataset: {len(all_training_variants)} total samples\")\n",
    "        print(f\"  ClinVar variants: {len(processed_variants)}\")\n",
    "        print(f\"  Reference benign: {len(normal_sequences)}\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR sampling reference genome: {e}\")\n",
    "    print(\"Continuing without normal sequences...\")\n",
    "    all_training_variants = processed_variants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8690142a",
   "metadata": {},
   "source": [
    "## 5 Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15a3a596",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training.model:=== Training Deletion Pathogenicity Predictor ===\n",
      "INFO:training.model:Dataset: 9559 pathogenic, 9511 benign\n",
      "INFO:training.model:Imbalance ratio: 1.01:1 (pathogenic:benign)\n",
      "INFO:training.model:Computed class weights: benign=1.003, pathogenic=0.997\n",
      "INFO:training.model:Train set: 7648 pathogenic, 7608 benign\n",
      "INFO:training.model:Test set: 1911 pathogenic, 1903 benign\n",
      "INFO:training.model:Building weighted ensemble (RF + GB + XGB)\n",
      "INFO:training.model:XGBoost scale_pos_weight: 0.99\n",
      "INFO:training.model:XGBoost included in ensemble\n",
      "INFO:training.model:Fitting ensemble with sample weights...\n",
      "INFO:training.model:Running 10-fold weighted cross-validation...\n",
      "INFO:training.model:Evaluating on held-out test set...\n",
      "INFO:training.model:Top 15 feature importances (Random Forest):\n",
      "INFO:training.model:  has_gene: 0.2729\n",
      "INFO:training.model:  gene_encoded: 0.0970\n",
      "INFO:training.model:  homopolymer_run: 0.0961\n",
      "INFO:training.model:  gene_length: 0.0893\n",
      "INFO:training.model:  complexity_score: 0.0837\n",
      "INFO:training.model:  at_content: 0.0786\n",
      "INFO:training.model:  gc_content: 0.0754\n",
      "INFO:training.model:  normalized_chr_position: 0.0713\n",
      "INFO:training.model:  is_known_disease_gene: 0.0678\n",
      "INFO:training.model:  deletion_length: 0.0297\n",
      "INFO:training.model:  log_deletion_length: 0.0235\n",
      "INFO:training.model:  repeat_content: 0.0102\n",
      "INFO:training.model:  is_small_del: 0.0021\n",
      "INFO:training.model:  cpg_islands: 0.0013\n",
      "INFO:training.model:  is_large_del: 0.0007\n",
      "INFO:training.model:=== Training Complete ===\n",
      "INFO:training.model:CV: Precision=0.898, Recall=0.969, F1=0.932, AUC=0.974\n",
      "INFO:training.model:Test: Precision=0.895, Recall=0.963, F1=0.928, AUC=0.975\n",
      "INFO:training.model:Models used: RF + GB + XGB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Performance (Mean + Std):\n",
      "  Precision:    0.8981\n",
      "  Recall:       0.9688\n",
      "  F1 Score:     0.9321\n",
      "  Specificity:  0.8895\n",
      "  AUC-ROC:      0.9742\n",
      "\n",
      "Test Set Performance:\n",
      "  Precision:    0.8949\n",
      "  Recall:       0.9628\n",
      "  F1 Score:     0.9277\n",
      "  AUC-ROC:      0.9751\n",
      "\n",
      "Test Set Confusion Matrix:\n",
      "  True Positives:  1840\n",
      "  True Negatives:  1687\n",
      "  False Positives: 216\n",
      "  False Negatives: 71\n",
      "\n",
      "Dataset Information:\n",
      "  Total variants:     11218\n",
      "  Training samples:   15256\n",
      "  Test samples:       3814\n",
      "  Number of features: 18\n"
     ]
    }
   ],
   "source": [
    "pathogenicity_predictor = DeletionPathogenicityPredictor(threshold = 0.6)\n",
    "\n",
    "try:\n",
    "    path_results = pathogenicity_predictor.train(\n",
    "        all_training_variants,\n",
    "        test_size=config.TEST_SIZE,\n",
    "        cv_folds=config.CV_FOLDS,\n",
    "    )\n",
    "    \n",
    "    # Cross-validation results\n",
    "    print(\"\\nCross-Validation Performance (Mean + Std):\")\n",
    "    print(f\"  Precision:    {path_results.get('cv_precision', 0):.4f}\")\n",
    "    print(f\"  Recall:       {path_results.get('cv_recall', 0):.4f}\")\n",
    "    print(f\"  F1 Score:     {path_results.get('cv_f1', 0):.4f}\")\n",
    "    print(f\"  Specificity:  {path_results.get('cv_specificity', 0):.4f}\")\n",
    "    print(f\"  AUC-ROC:      {path_results.get('cv_auc', 0):.4f}\")\n",
    "    \n",
    "    # Test set results\n",
    "    print(\"\\nTest Set Performance:\")\n",
    "    print(f\"  Precision:    {path_results.get('test_precision', 0):.4f}\")\n",
    "    print(f\"  Recall:       {path_results.get('test_recall', 0):.4f}\")\n",
    "    print(f\"  F1 Score:     {path_results.get('test_f1', 0):.4f}\")\n",
    "    print(f\"  AUC-ROC:      {path_results.get('test_auc', 0):.4f}\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    print(\"\\nTest Set Confusion Matrix:\")\n",
    "    print(f\"  True Positives:  {path_results.get('test_tp', 0)}\")\n",
    "    print(f\"  True Negatives:  {path_results.get('test_tn', 0)}\")\n",
    "    print(f\"  False Positives: {path_results.get('test_fp', 0)}\")\n",
    "    print(f\"  False Negatives: {path_results.get('test_fn', 0)}\")\n",
    "    \n",
    "    # Dataset statistics\n",
    "    print(\"\\nDataset Information:\")\n",
    "    print(f\"  Total variants:     {len(processed_variants)}\")\n",
    "    print(f\"  Training samples:   {path_results.get('n_train', 0)}\")\n",
    "    print(f\"  Test samples:       {path_results.get('n_test', 0)}\")\n",
    "    print(f\"  Number of features: {path_results.get('n_features', 0)}\")\n",
    "except ValueError as e:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ERROR: Model Training Failed\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Error: {e}\")\n",
    "    logger.error(f\"Training error: {e}\", exc_info=True)\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "except Exception as e:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ERROR: Unexpected Training Error\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Error: {e}\")\n",
    "    logger.error(f\"Unexpected training error: {e}\", exc_info=True)\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32245102",
   "metadata": {},
   "source": [
    "## Demonstration Using a Synthesized Pathogenic Deletion (Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5ac13d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92512812, 0.21463536])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# See: https://www.ncbi.nlm.nih.gov/clinvar/variation/246362/\n",
    "pathogenic_variant = {\n",
    "  \"uid\": \"CA10584575\",\n",
    "  \"gene\": \"BRCA1\",\n",
    "  \"title\": \"NM_007294.4(BRCA1):c.442-22_442-13del\",\n",
    "  \"chr\": \"17\",\n",
    "  \"start\": \"43099895\",\n",
    "  \"end\": \"43099904\",\n",
    "  \"assembly\": \"GRCh37\",\n",
    "  \"variant_type\": \"Deletion\",\n",
    "  \"consequence\": \"intronic variant, splice-altering\"\n",
    "}\n",
    "# See: https://www.ncbi.nlm.nih.gov/clinvar/variation/1584690/\n",
    "benign_variant = {\n",
    "  \"uid\": \"VCV001584690\",\n",
    "  \"gene\": \"NXN\",\n",
    "  \"title\": \"NM_022463.5(NXN):c.360+14del\",\n",
    "  \"chr\": \"17\",\n",
    "  \"start\": \"979305\",\n",
    "  \"end\": \"979305\",\n",
    "  \"assembly\": \"GRCh38\",\n",
    "  \"variant_type\": \"Deletion\",\n",
    "  \"consequence\": \"intron variant\"\n",
    "}\n",
    "pathogenicity_predictor.predict_proba([pathogenic_variant, benign_variant])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deltect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
